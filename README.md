# ğŸš— PrÃ¡ctica de IntegraciÃ³n: Pipeline de Datos TrÃ¡fico-MeteorologÃ­a

Este proyecto implementa un **pipeline de datos ETL (Extract, Transform, Load)** que integra informaciÃ³n heterogÃ©nea procedente de dos fuentes oficiales del Gobierno Vasco: la **DirecciÃ³n de TrÃ¡fico** y la **Agencia Vasca de MeteorologÃ­a (Euskalmet)**.

El objetivo es generar un dataset analÃ­tico que permita estudiar la correlaciÃ³n entre las condiciones climÃ¡ticas y los accidentes de trÃ¡fico.

---

## ğŸ“‹ CaracterÃ­sticas del Proyecto

* **Arquitectura:** ETL Batch (Procesamiento mensual).
* **Fuentes de Datos:**
    * **API TrÃ¡fico (OpenData Euskadi):** Incidencias en tiempo real e histÃ³ricas (JSON).
    * **API Euskalmet:** Predicciones y datos meteorolÃ³gicos por zonas (JSON).
    * **Mapeo Local:** Archivo CSV (`mapping_municipios.csv`) para normalizar y cruzar ubicaciones.
* **TransformaciÃ³n y Calidad:**
    * NormalizaciÃ³n de nombres de municipios.
    * Filtrado de incidencias (solo tipo "Accidente").
    * ValidaciÃ³n de esquema y tipos de datos con **Pandera**.
* **DataOps:** Entorno contenerizado con **Docker** para garantizar la reproducibilidad.
* **Salida:** Reporte consolidado en formato Excel (`.xlsx`).

---

## ğŸ“‚ Estructura del Proyecto

```text
practica_1/
â”œâ”€â”€ Apikey/
â”‚   â”œâ”€â”€ privateKey.pem       # (NECESARIO) Tu clave privada de Euskalmet
â”‚   â””â”€â”€ publicKey.pem        # Tu clave pÃºblica
â”œâ”€â”€ main.py                  # Script principal del pipeline ETL
â”œâ”€â”€ generate_mapping.py      # Herramienta auxiliar para generar el CSV de zonas
â”œâ”€â”€ mapping_municipios.csv   # Maestro de datos para cruzar TrÃ¡fico y Clima
â”œâ”€â”€ Dockerfile               # DefiniciÃ³n de la imagen del contenedor
â”œâ”€â”€ docker-compose.yml       # OrquestaciÃ³n del servicio
â”œâ”€â”€ pyproject.toml / uv.lock # GestiÃ³n de dependencias (uv)
â””â”€â”€ .env                     # Variables de entorno (Email, rutas)
```

---

## ğŸš€ Requisitos Previos

Para ejecutar este proyecto necesitas tener instalado:

1.  **Docker** y **Docker Compose**.
2.  Un par de claves (pÃºblica/privada) vÃ¡lidas para la API de Euskalmet.

-----

## ğŸ› ï¸ Instrucciones de EjecuciÃ³n (DataOps)

La forma recomendada de ejecutar el pipeline es mediante contenedores, asegurando que el entorno es idÃ©ntico al de desarrollo.

### 1\. ConfiguraciÃ³n de Credenciales

AsegÃºrate de colocar tu clave privada en la carpeta `Apikey`:

  * Ruta: `practica_1/Apikey/privateKey.pem`

### 2\. ConfiguraciÃ³n del Periodo (Opcional)

Por defecto, el script procesa un mes especÃ­fico. Si deseas cambiar las fechas, edita las constantes en `main.py`:

```python
START_DATE = datetime(2025, 11, 1)
END_DATE = datetime(2025, 11, 30)
```

### 3\. EjecuciÃ³n con Docker Compose

Abre una terminal en la carpeta del proyecto y ejecuta:

```bash
docker-compose up --build
```

**Â¿QuÃ© sucederÃ¡?**

1.  Docker construirÃ¡ la imagen con Python 3.13 y las librerÃ­as necesarias (`pandas`, `pandera`, `requests`, `pyjwt`, etc.).
2.  Se iniciarÃ¡ el contenedor `practica1_pipeline`.
3.  El script comenzarÃ¡ a descargar y procesar los datos dÃ­a a dÃ­a.
4.  Al finalizar, verÃ¡s un mensaje de Ã©xito y el contenedor se detendrÃ¡.

### 4\. Resultados

El reporte final aparecerÃ¡ automÃ¡ticamente en tu carpeta local (gracias al volumen montado en docker-compose) con el nombre:

  * ğŸ“„ `reporte_mensual_YYYYMM.xlsx`

-----

## âš™ï¸ EjecuciÃ³n Manual (Local)

Si prefieres ejecutarlo sin Docker, necesitarÃ¡s Python 3.13 y el gestor `uv` (o pip).

1.  Instalar dependencias:
    ```bash
    uv sync
    ```
2.  Ejecutar el script principal:
    ```bash
    uv run main.py
    ```
3.  (Opcional) Regenerar el archivo de mapeo si fuera necesario:
    ```bash
    uv run generate_mapping.py
    ```

-----

## âœ… Calidad del Dato

El proyecto utiliza la librerÃ­a **Pandera** para validar la integridad de los datos antes de guardarlos. Se comprueba:

  * Que el campo `cityTown` (Municipio) no estÃ© vacÃ­o.
  * Que el `incidenceType` sea estrictamente "Accidente".
  * Que las temperaturas (`temp_media`) estÃ©n dentro de rangos fÃ­sicos lÃ³gicos (-15ÂºC a 50ÂºC).
  * Que existan fechas vÃ¡lidas.

-----

## ğŸ“ Notas sobre la OptimizaciÃ³n

El pipeline implementa una **optimizaciÃ³n de consultas**:
En lugar de solicitar el clima de todos los municipios vascos cada dÃ­a, el script identifica primero dÃ³nde ocurrieron los accidentes diarios y solicita informaciÃ³n meteorolÃ³gica **exclusivamente** para esas ubicaciones, reduciendo drÃ¡sticamente el tiempo de ejecuciÃ³n y la carga sobre la API.